# HICD Crawler

Crawler em Node.js para extrair dados do sistema HICD (Sistema de Prontu√°rio) hospedado em https://hicd-hospub.sesa### üìä **Dados Extra√≠dos**

O crawler agora extrai dados completos de pacientes internados:

```json
{
  "nome": "NOME DO PACIENTE",
  "prontuario": "12345",
  "leito": "007.007-0001",
  "cid": "CID10 se dispon√≠vel",
  "dataInternacao": "05/08/2025 14:30",
  "diasInternado": 15,
  "clinica": "007",
  "registroEletronico": true,
  "kanban": true,
  "clinicaNome": "U T I",
  "clinicaCodigo": "007",
  "timestamp": "2025-08-06T02:05:56.719Z",
  "url": "https://hicd-hospub.sesau.ro.gov.br/..."
}
```

#### **Campos Extra√≠dos:**
- **Nome**: Nome completo do paciente
- **Prontu√°rio**: N√∫mero do prontu√°rio m√©dico  
- **Leito**: C√≥digo do leito (formato: XXX.XXX-XXXX)
- **CID**: C√≥digo CID10 (quando dispon√≠vel)
- **Data Interna√ß√£o**: Data e hora da interna√ß√£o
- **Dias Internado**: N√∫mero de dias desde a interna√ß√£o
- **Cl√≠nica**: C√≥digo da cl√≠nica
- **Registro Eletr√¥nico**: Indica se tem registro eletr√¥nico
- **Kanban**: Indica se tem acesso ao kanban

### ‚úÖ **Testado e Funcionando**

### üè• Cl√≠nicas Dispon√≠veis

O sistema HICD possui as seguintes cl√≠nicas para consulta de pacientes internados:

- **001** - EMERGENCIA - INTERNADOS
- **002** - C I P
- **003** - UIR 1 UNID-INTERN RAPIDA
- **004** - UIR 2 UNID-INTERN RAPIDA  
- **005** - UIR 3 UNID-INTERN RAPIDA
- **007** - U T I
- **008** - ENFERMARIA A
- **009** - ENFERMARIA B
- **010** - ENFERMARIA C
- **011** - ENFERMARIA D
- **012** - ENFERMARIA G
- **013** - ENFERMARIA H
- **014** - ISOLAMENTO
- **015** - ENFERMARIA J
- **016** - ENFERMARIA K
- **017** - ENFERMARIA L
- **018** - ENFERMARIA M
- **019** - HOSPITAL DIA
- **020** - SALA DE PROCEDIMENTO

### Headers e User-Agento.gov.br/prontuario/frontend/index.php

## ‚ú® Caracter√≠sticas

- **Autentica√ß√£o robusta**: Implementa retry autom√°tico para contornar o bug do sistema onde a primeira requisi√ß√£o sempre falha
- **Gerenciamento de sess√£o**: Mant√©m cookies/sess√£o ap√≥s login bem-sucedido
- **Rate limiting**: Delays configur√°veis entre requisi√ß√µes para n√£o sobrecarregar o servidor
- **Tratamento de erros**: Error handling robusto com logs detalhados
- **M√∫ltiplos formatos**: Salva dados extra√≠dos em JSON e CSV
- **Configura√ß√£o flex√≠vel**: Configura√ß√µes atrav√©s de arquivo `.env`

## üöÄ Funcionalidades Principais

### üìã Extra√ß√£o de Dados B√°sicos
- ‚úÖ **Lista de cl√≠nicas** dispon√≠veis no sistema
- ‚úÖ **Pacientes por cl√≠nica** com informa√ß√µes b√°sicas (nome, prontu√°rio, leito, CID, etc.)

### üë§ Dados Detalhados do Paciente
- ‚úÖ **Cadastro completo** com dados pessoais, endere√ßo e documentos
- ‚úÖ **Evolu√ß√µes m√©dicas** completas com hist√≥rico de todos os profissionais
- ‚úÖ **Informa√ß√µes de interna√ß√£o** (data, dias internado, cl√≠nica/leito)

### üìä An√°lise e Relat√≥rios
- ‚úÖ **Estat√≠sticas autom√°ticas** por cl√≠nica e atividade profissional
- ‚úÖ **Distribui√ß√£o de casos** por especialidade m√©dica
- ‚úÖ **Hist√≥rico temporal** das evolu√ß√µes
- ‚úÖ **Modo debug** para an√°lise de respostas HTML

### üîß Recursos T√©cnicos
- ‚úÖ **Parser HTML robusto** para extrair dados estruturados
- ‚úÖ **Formata√ß√£o JSON e CSV** para diferentes usos
- ‚úÖ **Logs detalhados** para acompanhamento e debug
- ‚úÖ **Tratamento de erros** com retry autom√°tico

## üöÄ Instala√ß√£o

1. Clone ou baixe os arquivos do projeto
2. Instale as depend√™ncias:

```bash
npm install
```

## ‚öôÔ∏è Configura√ß√£o

1. Edite o arquivo `.env` com suas credenciais:

```env
# Credenciais de login
HICD_USERNAME=seu_usuario
HICD_PASSWORD=sua_senha

# Configura√ß√µes de Rate Limiting
REQUEST_DELAY=1000
MAX_RETRIES=3

# Configura√ß√µes de Output
OUTPUT_FORMAT=json
OUTPUT_DIR=./output
```

## üéØ Uso

### Execu√ß√£o completa do crawler:

```bash
npm start          # Execu√ß√£o padr√£o
npm run full       # Execu√ß√£o completa otimizada (recomendado)
```

### Execu√ß√£o em modo de desenvolvimento:

```bash
npm run dev        # Com reinicializa√ß√£o autom√°tica
```

### Teste das funcionalidades:

```bash
npm run clinicas               # Exemplos espec√≠ficos de cl√≠nicas
npm run test-html              # Teste do parser HTML de pacientes
npm run test-extracao          # Teste de extra√ß√£o completa limitada
npm run test-paciente-detalhado    # Teste de cadastro e evolu√ß√µes de um paciente
npm run test-multiplos-detalhados  # Teste de m√∫ltiplos pacientes com dados completos
node teste-clinicas.js         # Teste completo das cl√≠nicas
node teste-clinicas.js --rapido    # Teste r√°pido
```

### Uso program√°tico:

```javascript
const HICDCrawler = require('./hicd-crawler');

async function exemplo() {
    const crawler = new HICDCrawler();
    crawler.setDebugMode(true); // Habilitar modo debug
    
    try {
        await crawler.login();
        
        // Buscar todas as cl√≠nicas dispon√≠veis
        const clinicas = await crawler.getClinicas();
        console.log(`Encontradas ${clinicas.length} cl√≠nicas`);
        
        // Buscar pacientes de uma cl√≠nica espec√≠fica
        const resultadoPacientes = await crawler.getPacientesClinica('007'); // UTI
        console.log(`UTI tem ${resultadoPacientes.pacientes.length} pacientes`);
        
        // Obter dados detalhados de um paciente
        const paciente = resultadoPacientes.pacientes[0];
        const cadastro = await crawler.getPacienteCadastro(paciente.prontuario);
        const evolucoes = await crawler.getEvolucoes(paciente.prontuario);
        
        console.log(`Paciente: ${cadastro.dadosBasicos.nome}`);
        console.log(`Evolu√ß√µes: ${evolucoes.totalEvolucoes}`);
        
        // Extrair dados de todas as cl√≠nicas
        const todosDados = await crawler.extractData();
        await crawler.saveData(todosDados);
        
    } finally {
        await crawler.logout();
    }
}
```

### Funcionalidades Espec√≠ficas:

#### üè• Buscar Cl√≠nicas
```javascript
const clinicas = await crawler.getClinicas();
// Retorna array com: { codigo, nome, index }
```

#### üë• Buscar Pacientes por Cl√≠nica
```javascript
const pacientes = await crawler.getPacientesClinica(
    '007',          // c√≥digo da cl√≠nica
    '',             // refer√™ncia (opcional)
    'Silva',        // filtro nome (opcional)
    'N'             // ordem: N=nome, C=cl√≠nica+leito (opcional)
);
```

## üèóÔ∏è Estrutura do Projeto

```
hicd-bot/
‚îú‚îÄ‚îÄ hicd-crawler.js     # Classe principal do crawler
‚îú‚îÄ‚îÄ index.js            # Script de execu√ß√£o principal
‚îú‚îÄ‚îÄ test-crawler.js     # Script de teste
‚îú‚îÄ‚îÄ package.json        # Depend√™ncias e scripts
‚îú‚îÄ‚îÄ .env               # Configura√ß√µes (credenciais)
‚îú‚îÄ‚îÄ README.md          # Este arquivo
‚îî‚îÄ‚îÄ output/            # Diret√≥rio de sa√≠da (criado automaticamente)
    ‚îú‚îÄ‚îÄ hicd-data-*.json
    ‚îú‚îÄ‚îÄ hicd-data-*.csv
    ‚îî‚îÄ‚îÄ hicd-log-*.txt
```

## üîß Funcionalidades T√©cnicas

### Autentica√ß√£o
- **URL de Login**: `https://hicd-hospub.sesau.ro.gov.br/prontuario/frontend/controller/controller.php`
- **M√©todo**: POST
- **Payload**: `Param=LOGIN&user=usuario&pass=senha&session=undefined`
- **Bug do Sistema**: A primeira requisi√ß√£o sempre falha, implementamos retry autom√°tico

### Headers e User-Agent
O crawler usa headers realistas para simular um navegador:
- User-Agent do Chrome
- Headers de Accept apropriados
- Referer correto
- Cookies de sess√£o mantidos automaticamente

### Rate Limiting
- Delay configur√°vel entre requisi√ß√µes (padr√£o: 1000ms)
- M√°ximo de tentativas configur√°vel (padr√£o: 3)
- Delays aumentados em caso de erro

## üìä Formato dos Dados

### JSON
```json
[
  {
    "url": "https://...",
    "timestamp": "2025-08-05T10:30:00.000Z",
    "title": "T√≠tulo da p√°gina",
    "extractedData": {
      // Dados espec√≠ficos extra√≠dos
    }
  }
]
```

### CSV
Formato tabular com todas as colunas dos dados extra√≠dos.

## üêõ Tratamento do Bug do Sistema

O sistema HICD tem um bug conhecido onde a primeira requisi√ß√£o de login sempre falha. O crawler implementa a seguinte estrat√©gia:

1. **Primeira tentativa**: Sempre falha (esperado)
2. **Aguarda 2 segundos**
3. **Segunda tentativa**: Geralmente bem-sucedida
4. **Retry adicional**: Se necess√°rio, at√© atingir MAX_RETRIES

## üìù Logs

O crawler gera logs detalhados durante a execu√ß√£o:
- `[LOGIN]`: Opera√ß√µes de autentica√ß√£o
- `[EXTRA√á√ÉO]`: Processo de coleta de dados
- `[SALVAMENTO]`: Opera√ß√µes de arquivo
- `[LOGOUT]`: Encerramento de sess√£o

## ‚ö†Ô∏è Considera√ß√µes Importantes

1. **Respeite o servidor**: Use delays apropriados entre requisi√ß√µes
2. **Credenciais seguras**: Nunca commite o arquivo `.env` com credenciais reais
3. **Adapte os seletores**: Os seletores CSS/jQuery podem precisar ser ajustados conforme a estrutura real das p√°ginas
4. **Teste primeiro**: Use `npm test` antes de executar extra√ß√µes completas

## üîÑ Personaliza√ß√£o

Para extrair dados espec√≠ficos, edite o m√©todo `extractPageData()` na classe `HICDCrawler`:

```javascript
async extractPageData(url) {
    const response = await this.client.get(url);
    const $ = cheerio.load(response.data);

    // Customize os seletores conforme necess√°rio
    const pageData = {
        patientName: $('.patient-name').text().trim(),
        patientId: $('.patient-id').text().trim(),
        records: []
    };

    // Adicione sua l√≥gica de extra√ß√£o aqui
    
    return pageData;
}
```

## üÜò Solu√ß√£o de Problemas

### Erro de login
- Verifique credenciais no `.env`
- Confirme que o sistema est√° online
- Aumente o n√∫mero de MAX_RETRIES

### Dados n√£o extra√≠dos
- Verifique os seletores CSS no m√©todo `extractPageData()`
- Use o modo de debug para ver o HTML das p√°ginas
- Confirme que voc√™ est√° logado corretamente

### Problemas de rede
- Aumente o timeout nas configura√ß√µes do axios
- Reduza a frequ√™ncia de requisi√ß√µes aumentando REQUEST_DELAY
- Verifique sua conex√£o com o servidor

## üìÑ Licen√ßa

MIT License - Veja o arquivo de licen√ßa para detalhes.
